# CRITICAL PERFORMANCE: Must set NSA_FORCE_SEL_MASK=1 environment variable
# Without it, training runs at <10 tok/s instead of 9,200+ tok/s
# Example: NSA_FORCE_SEL_MASK=1 python scripts/train_showcase.py

model:
  dim: 768
  n_layers: 12
  n_heads: 12
  n_kv_groups: 2
  d_k: 64
  d_v: 64
nsa:
  l: 32
  d: 16
  l_sel: 64
  n_sel: 16
  w: 512
  phi: "avg"
data:
  tokenizer: "byte"
runtime:
  device: "cuda"
  precision: "bf16"
  use_flash: true
  use_triton_sel: false
  gradient_checkpointing: true
train:
  steps: 50000
  seq_len: 2048
  batch_size: 1        # single GPU safety (fits in ~49 GB)
  lr: 2.0e-4
  lr_schedule: "cosine"
  warmup_steps: 2000
  weight_decay: 0.01
  grad_clip: 1.0
  accumulate_grad_batches: 1
  log_every: 20
  eval_every: 1000
  save_every: 5000
  seed: 1337
  out_dir: "artifacts/m7c_125m_1xa100_prod"
